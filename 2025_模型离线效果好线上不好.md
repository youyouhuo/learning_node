### 离线效果好，在线效果差的原因：
https://yangxudong.github.io/why-rec-model-fail/

总结几点：
- a. 离线在线特征不一致：实现存在bug，特征存在延迟
- b. 数据泄露：数据泄露，特征泄露：训练数据泄露通常是测试数据或者未来的数据混合在了训练数据中，特征泄露是指特征中包含了关于真实标签的信息。
- c. 数据分布不一致：分布随时间发生偏移（大促，季节，流行，审美变化等等）；分布随地理位置发生偏移（南方人，北方人等），数据分布在不同场景不同（大小场景数据融到一起，大场景主导了训练）；冰山效应（线训练用的是有偏的冰山上的数据，而在线上预估的时候，需要预测的是整个冰山的数据，冰山效应在实验模型与baseline的模型相差较大时很容易造成较大的影响，比如实验模型是个性化推荐的DNN模型，而baseline是一个热门推荐的策略，这个时候新模型往往会推荐很多baseline不会展现出来的之前很少曝光的物品，而这些物品是否能够被高效点击和转化有一定的不确定性。新模型一开始相当于都是在拟合老模型产生的样本，刚上线效果如果比较差，经过一段时间迭代，影响的样本分布慢慢趋近于新模型，也能收敛，但效率较低。缓解冰山效应的两个思路：a)对无偏数据进行上采样
这里的无偏是相对的，可以是随机/探索流量产生的样本，也可以是新模型产生的样本。大概意思，就是尽可能利用这些对新模型有利的样本 b)线上线下模型融合,新模型预估分数pctr和老模型预估分数 pctr 直接在线上做线性融合 out = a*pctr_new + (1-a)pctr_old，刚上线的时候平滑系数 a选取比较小，随着慢慢迭代,a慢慢放大）
- d. 模型过拟合：一直使用同一个测试集来评估，导致过分拟合一个测试集
- e. 离线在线评估不一致：我们曾遇到过离线AUC 很高（或提升很多）但 CTR 效果不理想，（AUC指标反应的是模型把全局任意一对正负样本中的正样本排序在负样本之前的概率。离线计算AUC指标其实对应了模型对多个请求的样本之间进行排序，而点击率提升需要模型对一个请求内部的多个 Item 进行排序。模型的全局排序能力强不一定就表示同一次请求内部的item排序能力强。GAUC(Group AUC)的指标可能更加接近线上CTR的点击偏好。这里的Group表示按照用户Session来分组评估样本。）gauc实现 https://github.com/qiaoguan/deep-ctr-prediction/blob/master/DeepCross/metric.py 【之前也有一个版本是 shenweichen的，大概实现应该都差不多】
- f. 其他原因：
