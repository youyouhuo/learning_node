### 1.网络方式
* dcn   原理解读 ([知乎](https://zhuanlan.zhihu.com/p/120433070)) tensorflow实现[代码](https://github.com/tensorflow/recommenders/blob/main/tensorflow_recommenders/layers/feature_interaction/dcn.py)
  >> 论文
  >> * Deep & Cross Network for Ad Click Predictions
  >>>
  >>> * we stack the embedding vectors, along with the normalized dense features xdense, into one vector and feed x0 to the network.（离散型特征经过embedding后，和连续型特征拼接到一起作为最终的输入）
  >>>
  >>> * the small number of parameters of the cross network has limited the model capacity. To capture highly nonlinear interactions,
we introduce a deep network in parallel
  >>>
  >>> * 最后是deep层和cross层的的结果拼接到一起，乘以w后过激活函数 res = sigmoid(w*[xdeep,xcross])
  >>>
  >>> * Adam optimizer、 batch size is set at 512、Batch normalization was applied to the deep network 、 gradient clip norm
was set at 100、used early stopping， as we did not find L2 regularization or dropout to be effective
  >>>
  >>> * 这里的实现 tensorflow实现[代码](https://github.com/tensorflow/recommenders/blob/main/tensorflow_recommenders/layers/feature_interaction/dcn.py) 虽然是tensorflow的官方实现，但是和实际的论文有稍微差别,论文中的原始实现是 $x_{l+1}=x_0*x_{l}^T*w+b+x_{l}$  而这里的实现是 $x_{l+1}=x_0*(x_{l}^T*w+b)+x_{l}$ 有一些区别。
  >>>
 * DCN V2: Improved Deep & Cross Network and Practical Lessons
for Web-scale Learning to Rank Systems
>> 论文
  >> * DCN V2: Improved Deep & Cross Network and Practical Lessons for Web-scale Learning to Rank Systems
  >>>
  >>> * dcn的缺点：1）The expressiveness of its cross network is limited (cross网络的表达能力有限) 2)The polynomial class reproduced by the cross network is only characterized by 𝑂(input size) parameters, largely limiting its flexibility in modeling random cross patterns(cross网络再现的多项式类仅由 𝑂（输入大小）参数来表征，很大程度上限制了其对随机交叉模式建模的灵活性) 3) the allocated capacity between the cross network and DNN is unbalanced，This gap significantly increases when applying DCN to large-scale production data. An overwhelming portion of the parameters will be used to learn implicit crosses in the DNN (cross网络和dnn网络分配的容量不平衡，当DCN应用于大规模生产数据时，这种差距显着增加。绝大多数参数将用于学习 DNN 中的隐式交叉)
>>> * dcnv2 版本：1）采用是 $x_{l+1}=x_0*(x_{l}^T*w+b)+x_{l}$ *****计算 2）输入部分也是离散型embedding后和连续型拼接到一起 3）最后，设计了类似dcn的并行方式  res=sigmoid(w*[xdeep,xcrossv2]) , 也有先dcnv2 后 dnn的串行方式

