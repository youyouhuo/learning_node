### [推荐系统系列之排序模型的调优实践](https://aws.amazon.com/cn/blogs/china/optimization-practice-of-the-ranking-model-of-the-recommendation-system-series/)
- 方式1： 每天去过去n天数据训练
- 方式2：每天只用最近一天的数据在base上增量更新
- 方式3：每天天内小时级进行增量更新，然后天级使用方式1做更新

### [小红书高时效推荐系统背后的技术升级](https://juejin.cn/post/7225058326576939068)
- 方式1： base 模型： 与传统的天级训练一致，每天凌晨训练前一天完整的数据
- 方式2：增量模型： 基于当天跑出来 base 模型，继续一小时一次训练今天实时的数据，但固定全连接网络参数不更新，只更新 sparse embedding


### [蘑菇街首页推荐视频流——增量学习与wide&deepFM实践（工程+算法）](https://zhuanlan.zhihu.com/p/212647751)
- 我们的增量学习架构中，全量模型训练n天执行一次，n>=1，增量训练每小时执行一次。每次增量训练时，都会restore当前增量对应全量版本的checkpoint和上一次增量版本的checkpoint，对当前增量样本的validation验证集进行评估。我们可以得到每一次增量训练过程中的最优AUC（或者固定epoch的AUC），与全量版本的AUC和上次增量版本的AUC进行比较，得到离线的AUC diff。这里的AUC评估基于同一份验证集，从离线AUC的表现来看，随着时间的推移，增量学习的有效性愈发明显。若两天不更新模型，离线AUC的损失高达3.5%。
- 全量训练与增量训练的协同
  - 每次启动增量样本构建流程时，会自动拉取从上一次构建完的样本（打结束标）到当前时刻的所有样本进行构建。同样的，每次启动增量模型训练时，会捞出所有迄今为止未训练样本对应的增量版本，统一在当前训练流程中进行训练，避免出现样本被漏训练的情况。
  - 全量模型训练与增量模型训练并非同一任务，因为其超参和配置不同。每次全量模型训练完成后，所保存的模型checkpoint路径以当前全量任务命名，增量模型训练无法reload全量任务下的ckpt（任务id无法互传）。如何打通全量与增量模型训练呢？我们在每次完成全量模型的训练后，将全量ckpt拷贝到增量任务所在目录下。注意，copy操作只允许chief节点操作，因为在分布式框架下，若worker快于chief完成训练，并在export模型后执行copy操作，可能会导致chief节点的ckpt保存出现异常。

### [分钟级在线深度学习在手淘信息流排序模型中的探索与实践](https://mp.weixin.qq.com/s/_ZJBxkvETBpT_X0prMsT_A?st=CDBD9F9D797BDA861C2989E17106483A769B2D6DEEBC14E1C4C82F12EAC0E80EF065FAA07F0B3BFB490EE0DF210747AFF53CDA2E209163869634123AFDD56EAE185942926B72986E5AF3D8247BBC34D3A68169EE88553F4CD2B383DAAB1E8A16B53E196D49032B27121430E43EB795135F31613755BF6231A0BD6615D1E26CAE52010D7A159B630379548013713A1452&vid=1688850536000255&cst=4D50C275DCCB304A2C1648A26A4802713DD2FE88F7F181AF523997F1675CB2BD5DDC9FC6D3F8E80090EB5C8BC01493C6&deviceid=cca6e4fd-fc1c-4249-b32c-6147f4bb18bf&version=3.1.0.2353&platform=mac)
- 等待T时刻
- - 如果T时刻内有正样本，则下发，否则下发负样本
  - 期间，如果T时刻后还变成了正样本，则标记为Retraction样本，对于这部分样本，在学习label为1的同时加上反向更新label为0时的梯度【采用PU Loss对其训练进行修正，核心思想就是对于这部分Retraction的样本，除了使用正样本进行梯度下降，还会对相应的负样本进行一个反向的梯度下降，抵消之前观察到为负样本对loss的影响】
