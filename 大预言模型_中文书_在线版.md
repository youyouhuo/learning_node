### 链接见：https://llmbook-zh.github.io/


### 笔记
> 1.各代模型的功能情况

>> 1990s: n-gram统计模型【具备一定生成能力，辅助解决部分任务，数据系数影响严重】，

>> 2013【RNN-LM，word2vec，有效克服数据系数问题，无监督学习语义特征表示，缺乏知识、可迁移性差】，

>> 2018【ELMo,BERT,GPT-1/2，有效捕捉上下文语义，任务迁移性有了显著提升，仍然需要监督数据微调】，

>> 2022【GPT3/4,ChatGPT,Claude，规模扩展带来性能重要提升，通用的任务求解途径，学习成本高，适配灵活性差】

>2. 大语言模型的能力特点

>> 具有丰富的世界知识【参数规模大，数据规模大，充分学习到海量世界知识】

>> 具有较强的通用任务解决能力 【下一个词预测任务可以看成是一个多任务学习过程，不同词的预测可能涉及到不同训练任务，如请个分类 xxx真好看，数值计算，xxx=7，知识推理 中国最大的省份是新疆】

>> 具有较好的复杂任务推理能力

>> 具有较强的人类指令遵循能力【任务输入与执行结果均通过自然语言进行表达。通过预训练和微调，大模型具备人类指令遵循能力】

>> 具有较好的人类对齐能力。【通过强化学习使得模型进行正确行为的加强以及错误行为的规避，进而建立较好的人类对齐能力】

>> 具有可拓展的工具使用能力【可以通过微调、上下文学习等方式掌握外部工具的使用、如搜索引擎和计算器】
