### 目前的思路
>之前思路不成功原因分析：
>> * 没有将item的信息进行融合（只使用了用户策略的特征，大量的embedding学习，加上没有和item交叉，在不同的item之间没有区分)
>>> * 解决方案1：将大量的embedding进行替换-------特征处理成简单的交叉类特征，降低学习难度
>>> * 解决方案2：加入user和item的交叉，提升不同item的区分能力
>> * 融合的参数值学习不充分（输出weight和bias没有个性化，或者根本没有学习好）
>>> * 解决方案1：在base基础上，在用a+f(wx+b)的方式来进行学习，最差情况下，网络f没学习信息，使用的还是原始的中心值，降低学习难度
>>> * 解决方案2：加入user和item的交叉，提升不同item的区分能力
>>> * 解决方案3：将奖励进行降级，只学习播放时长，同时考虑只用请求内的时长
>> * 融合的参数采用ddpg训练不稳定
>>> * 从离线数据来看，用户大多数情况下只有1~2个请求，在这种情况下，不存在多轮交互，所以ddpg这种方式其实并不是很适合（需要下一个状态的预估值），除非是进行隔天的操作，为了方便，这里还是采用单请求的方式
>>* 融合的参数探索太过剧烈导致效果波动大
>>> * 将探索的幅度进行缩小，采用predict + N(0,1)的方式进行探索，每次小步快跑进行尝试
