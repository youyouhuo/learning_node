### 样本加权方式的一些学习资料

[点击+时长时加权方式](https://zhuanlan.zhihu.com/p/281434497) 和这个的内容是一样的[推荐系统之样本加权](https://mp.weixin.qq.com/s/lLYuqlL2ExSNwCetRo_deA)
一个很自然想到的解决方法是做时长平滑，比如log(时长+1)，但是相对于二分类logloss来说，这样的权重还是太大了，权重会压过损失本身，所以需要进一步对时长做归一化，先对时长做截断处理，比如统计下图文视频的阅读时长分位数，然后做适当截断到maxtime，再log(时长+1)/maxtime，这样处理过后，权重就比较合理了。

[样本生而不等——聊聊那些对训练数据加权的方法](https://zhuanlan.zhihu.com/p/53545036)

[蘑菇街首页推荐对目标优化至reweight实践](https://zhuanlan.zhihu.com/p/271858727)
- 取log的时候，有选择一定的底数，即log(a,c)【直接使用原始log(c)函数时，对数据压缩比较严重，缺少一定的区分度】

[UC 信息流推荐模型在多目标和模型优化方面的进展](https://blog.51cto.com/u_15060460/2676817)

[推荐系统中的多任务学习与多目标排序工程实践（下） ](https://zhuanlan.zhihu.com/p/441117034)
- 多目标融合
- 多目标搜参

