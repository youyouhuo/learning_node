### å¼ºåŒ–å­¦ä¹ åœ¨æ¨èçš„åº”ç”¨

#0. Reinforcement Learning based Recommender Systems: A Survey ï¼ˆ2022 june acm)

#1. A Survey of Deep Reinforcement Learning in Recommender Systems: A Systematic Review and Future Directionsï¼ˆarXiv-2021.09ï¼‰
  
 (blog)https://cloud.tencent.com/developer/article/1881235   ï¼ˆä¸Šé¢è®ºæ–‡å¯¹åº”çš„åšå®¢ï¼‰
 
 
#2. å¼ºåŒ–å­¦ä¹ åœ¨ç¾å›¢"çŒœä½ å–œæ¬¢"çš„åº”ç”¨ https://tech.meituan.com/2018/11/15/reinforcement-learning-in-mt-recommend-system.html

#3. å¼ºåŒ–å­¦ä¹ åœ¨äº¬ä¸œçš„åº”ç”¨ https://www.6aiq.com/article/1547826520120

#4. youtube value-baseçš„å¼ºåŒ–å­¦ä¹ æ¨èç³»ç»Ÿ https://blog.csdn.net/weixin_44289754/article/details/119122740

#5. åŸºäºå¼ºåŒ–å­¦ä¹ çš„æ¨èç ”ç©¶ç»¼è¿° ï¼ˆè®¡ç®—æœºç§‘å­¦ï¼‰https://www.jsjkx.com/CN/article/openArticlePDF.jsp?id=20212

#6. å¼ºåŒ–å­¦ä¹ åœ¨ ç¾å›¢ äº¬ä¸œ å¾®è½¯çš„å®è·µï¼ˆçŸ¥ä¹ï¼‰ https://zhuanlan.zhihu.com/p/355041851

#7. (å¾®è½¯drn paperï¼‰DRN: A Deep Reinforcement Learning Framework for News Recommendation

#8. çŒœæ‚¨æ‰€æƒ³ï¼šæ·˜å®æœç´¢/æ¨èç³»ç»ŸèƒŒåæ·±åº¦å¼ºåŒ–å­¦ä¹ ä¸è‡ªé€‚åº”åœ¨çº¿å­¦ä¹ çš„å®è·µä¹‹è·¯ https://toutiao.io/posts/9j6ze2/preview ï¼ˆåŸå§‹é“¾æ¥ https://mp.weixin.qq.com/s/gKlyvv8hzlHRAOLRlVV3dw?ï¼‰

#9. ç»“åˆç”¨æˆ·é•¿çŸ­æœŸå…´è¶£çš„æ·±åº¦å¼ºåŒ–å­¦ä¹ æ¨èæ–¹æ³•ï¼ˆä¸­æ–‡ä¿¡æ¯å­¦æŠ¥ï¼‰  http://jcip.cipsc.org.cn/CN/Y2021/V35/I8/107

#10. Flink + å¼ºåŒ–å­¦ä¹ æ­å»ºå®æ—¶æ¨èç³»ç»Ÿï¼ˆåšå®¢å›­---ç²¾è¯»ï¼‰  https://www.cnblogs.com/massquantity/p/13842139.html

#Top-ğ¾ Off-Policy Correction for a REINFORCE Recommender System
  æ•´ä½“ä¸Šï¼Œä½¿ç”¨äº†Chaos Free RNN (CFN) å»ºæ¨¡çŠ¶æ€ä¹‹é—´çš„è½¬ç§»
  ä½¿ç”¨ æ¢¯åº¦ä¸å›ä¼ çš„betaç½‘ç»œå¤„ç†ç¦»çº¿è®­ç»ƒä¸­çš„data biasï¼Œ
  ä¸ºäº†é™ä½çŠ¶æ€ç©ºé—´ï¼Œå…ˆä½¿ç”¨è¿‘é‚»æœç´¢Kä¸ªï¼Œç„¶åé¢„ä¼°è¿™kä¸ªactionçš„å€¼ã€‚
  ä¸ºäº†é™ä½æ–¹å·®ï¼Œä½¿ç”¨weight clipping
  ï¼ˆblog)http://wd1900.github.io/2019/06/23/Top-K-Off-Policy-Correction-for-a-REINFORCE-Recommender-System-on-Youtube/
  
 #slateQ ï¼ˆblog) https://blog.csdn.net/zackerzhuang/article/details/100978955   ä¸ https://blog.csdn.net/qq_16234613/article/details/105339645
    æ•´ä½“ä¸Šåœ¨æ’åºå±‚ä½¿ç”¨sarsaç®—æ³•æ¥è¿›è¡Œå­¦ä¹ ã€‚
    2ä¸ªåŸºæœ¬å‡è®¾ï¼š
              
                single choiceï¼šç”¨æˆ·ä¸€æ¬¡åªåœ¨æ¨èåˆ—è¡¨ä¸­ç‚¹å‡»ä¸€ä¸ªæ¨èé¡¹æˆ–ä¸ç‚¹å‡»ä»»ä½•æ¨èé¡¹
               
               RTDS(Reward/transition dependence on selection) ç”¨æˆ·æ ¹æ®é€‰æ‹©æ¨èé¡¹è€Œä¼šäº§ç”Ÿä¸åŒçš„å›æŠ¥å’ŒçŠ¶æ€è½¬ç§»ï¼Œæ²¡é€‰æ‹©æ—¶ï¼Œå°±æ˜¯æ²¡æœ‰è½¬ç§»ã€‚
    
 #jd-Deep Reinforcement Learning for List-wise Recommendations
 
 æ•´ç¯‡æ–‡ç« æ ¸å¿ƒæ˜¯å»ºç«‹ä¸€ä¸ªç¦»çº¿æ¨¡æ‹Ÿå™¨æ¥æ¨¡æ‹Ÿçº¿ä¸Šçš„æ¨èè¿‡ç¨‹ï¼Œæ²¡æœ‰è¿›è¡ŒçœŸå®çš„abæµ‹è¯•
 
 æ•´ä½“ä¸Šé‡‡ç”¨ddpgæ¥æ­å»ºï¼š
    
    æ¨¡æ‹Ÿæ—¶çš„å¥–åŠ±ï¼š
      ç”±äºæ˜¯ç¦»çº¿çš„æ¨¡æ‹Ÿï¼Œæ‰€ä»¥ä¸èƒ½ç›´æ¥æ”¶é›†åˆ°ç”¨æˆ·çš„åé¦ˆï¼Œè¿™é‡Œåšäº†ä¸€ä¸ªå‡è®¾ï¼šæœ‰ç›¸ä¼¼å…´è¶£çš„ç”¨æˆ·å¯¹åŒä¸€ä¸ªitemä¼šåšå‡ºç›¸ä¼¼çš„å†³ç­–ã€‚å› æ­¤åŸºäºæ­¤ï¼Œå¯ä»¥é€šè¿‡å†å²çš„<st,at> æ¥å¯¹æ¨¡æ‹Ÿæ—¶äº§ç”Ÿçš„çŠ¶æ€åŠ¨ä½œç”Ÿæˆå¥–åŠ±ã€‚
      ä½¿ç”¨ä¸€ä¸ªmemoryä¿å­˜ (s,a)->rçš„æ˜ å°„
      å¯¹äºç®—æ³•äº§ç”Ÿçš„(s,a)ï¼Œé€šè¿‡å’Œmemoryé‡Œé¢çš„ä¿æŒçš„æ˜ å°„è®¡ç®—ç›¸ä¼¼åº¦ï¼Œç„¶åè¿‘ä¼¼äº§ç”Ÿæ˜ å°„ã€‚ï¼ˆè¿™é‡Œçš„sæ˜¯Nä¸ªæ­£åé¦ˆçš„itemæ„æˆçš„ï¼Œæ¯æ¬¡æœ‰æ–°çš„itemï¼Œå°±åˆ é™¤æœ€æ—§çš„é‚£ä¸ªitemï¼‰
    
    åŠ¨ä½œç½‘ç»œï¼š 
        æ¯æ¬¡æ¨èkä¸ªitem
        s->w   é€šè¿‡çŠ¶æ€å­¦ä¹ kä¸ªwï¼Œæ¯ä¸ªwå¯¹åº”ä¸€ä¸ªä½ç½®ä¸Šçš„å‚æ•°ã€‚
        åŠ¨ä½œäº§ç”Ÿï¼š scoreti=wti*embi    é€šè¿‡è¿™kä¸ªwtiä¹˜ä»¥itemçš„embeddingæ¥è®¡ç®—æœ€ç»ˆçš„å¾—åˆ†ï¼Œç„¶åæ¯ä¸ªä½ç½®å–å¾—åˆ†æœ€é«˜çš„itemä½œä¸ºæœ€ç»ˆåŠ¨ä½œatiï¼ˆå‰é¢ä½ç½®å–äº†å°±ä»åé¢ä½ç½®çš„å€™é€‰ä¸­åˆ é™¤ï¼‰
    criticç½‘ç»œï¼š
        è¾“å…¥st å’Œ ati......atk ï¼Œè¾“å‡ºQ(st,at)    è¿™é‡Œatæ˜¯ kä¸ªitemçš„ç»Ÿ-è¡¨ç¤º
    
    æ•´ä½“æ‰§è¡Œæµç¨‹å¦‚ä¸‹ï¼š    
        
        æ ¹æ®ç”¨æˆ·çš„sessionæ»‘åŠ¨ï¼Œéå†æ¯ä¸€ä¸ªsession,
        æ ¹æ®å‰ä¸€ä¸ªsessionå¾—åˆ°çš„çŠ¶æ€sä½œä¸ºs0ï¼Œè¿›è¡Œé¢„æµ‹çŠ¶æ€atï¼Œå¹¶è®¡ç®—å¯¹åº”çš„å¥–åŠ±
        æ›´æ–°çŠ¶æ€ï¼Œå¹¶æŠŠstï¼Œatï¼Œrtï¼Œst+1ä¿å­˜èµ·æ¥ï¼Œä¿å­˜ä¸ºD
        
        ä»Dä¸­é‡‡æ ·Nä¸ªæ ·æœ¬ï¼Œæ›´æ–°acotrå’Œcriticçš„çš„å‚æ•°
        
  #jd1-Deep Reinforcement Learning for Page-wise Recommendations
      
      çŸ¥ä¹ï¼šhttps://zhuanlan.zhihu.com/p/59081462
        
        æ ¸å¿ƒçš„è´¡çŒ®ç‚¹ï¼š
          1.æå‡ºä¸€ä¸ªèƒ½å¤Ÿå­¦ä¹ ä¸€é¡µä¸­itemæ€ä¹ˆåˆ†å¸ƒçš„æ¨èç®—æ³•
          2.æå‡ºä¸€ä¸ªåŸºäºddpgçš„æ·±åº¦å¼ºåŒ–å­¦ä¹ ç®—æ³•æ¥å­¦ä¹ 
          3.æ–‡ä¸­æœ€æœ‰çš„æµ‹è¯•ä¹Ÿæ˜¯é‡‡ç”¨æ¨¡æ‹Ÿæ¥å®Œæˆï¼Œå¹¶æ²¡æœ‰çœŸå®çš„çº¿ä¸Šabæµ‹è¯•
         
        çŠ¶æ€æ„å»ºï¼š
          
          ä¸€é¡µä¸­çš„itemçœ‹æˆæ˜¯ä¸€ä¸ªM=h*w ä¸ªitemç»„æˆçš„2då†…å®¹ã€‚æ¯ä¸€ä¸ªitemåŒ…å«å®ƒçš„side infoä½œä¸ºè¾“å‡ºï¼Œå³xi=(id,category,feedback),å…¶ä¸­çš„feedbackåŒ…å«ç”¨æˆ·è·³è¿‡ï¼Œç‚¹å‡»ï¼Œè´­ä¹°ç­‰è¡Œä¸ºã€‚
          
          æŠŠä¸€é¡µçš„itemçœ‹æˆæ˜¯ä¸€ä¸ª2dçš„å›¾ç‰‡ï¼Œä½¿ç”¨å·ç§¯æå–ç‰¹å¾ï¼Œpi=conv2d(Xi)
          
          p1,p2,....,ptåˆç”¨gruæ¥å­¦ä¹ æ—¶é—´ä¸Šçš„å…³ç³»ï¼Œå¾—åˆ°h1,h2,.....ht
          
          ä½¿ç”¨attentionç»“æ„æ¥æ¥ä»hiä¸­å­¦ä¹ åˆ°å½“å‰çš„çœŸæ­£çŠ¶æ€s_current
          
       åŠ¨ä½œçš„æ„å»ºï¼š
          a_current = deconv2d(s_current) ,å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œè¿™é‡Œçš„a_currentå’Œpiæ˜¯ä¸åŒçš„ï¼Œå‰è€…åªåŒ…å«äº†itemçš„embeddingä¿¡æ¯ï¼Œè€Œåè€…è¿˜æœ‰side infoå’Œç”¨æˆ·åé¦ˆä¿¡æ¯ã€‚
      
      
       criticçš„æ„å»ºï¼š
          
          a_currentæ˜¯ä¸€ä¸ª2dçš„åŒ…å«item embeddingä¿¡æ¯çš„è¡¨ç¤ºï¼Œè¦è½¬åŒ–æˆæœ€ç»ˆçš„åŠ¨ä½œï¼Œè¿˜éœ€è¦ä¸€æ­¥ï¼Œa=conv2d(a_current),è¿™é‡Œçš„aå°±æ˜¯è¾“å…¥åˆ°dqnä¸­çš„åŠ¨ä½œäº†ã€‚
          
       
       è®­ç»ƒæµç¨‹ï¼š
        
          ä¸Šé¢çš„a_currentæ˜¯ä¸€ä¸ª2dçš„åŒ…å«item embeddingä¿¡æ¯çš„è¡¨ç¤ºï¼Œä½†æ˜¯å¹¶ä¸æ˜¯æ¯ä¸€ä¸ªembeddingéƒ½æœ‰å¯¹åº”çš„idï¼Œæ‰€ä»¥ï¼Œè¿˜éœ€è¦ä¸€ä¸ªmappingçš„è¿‡ç¨‹ï¼Œæ‰¾åˆ°æœ€åŒ¹é…çš„çœŸå®item idã€‚
          
          åœ¨online trainingé˜¶æ®µï¼Œé€šè¿‡cosine ç›¸ä¼¼åº¦å°†a_current å’Œ a_val è¿›è¡Œå…³è”èµ·æ¥ã€‚ç„¶åå¯ä»¥æŠŠa_valæ¨èç»™ç”¨æˆ·ï¼Œè·å–åé¦ˆ r=sum(reward(ei))
          
          åœ¨ offline trainingé˜¶æ®µï¼Œç”±äºä½¿ç”¨çš„æ˜¯ç”¨æˆ·çš„å†å²è®°å½•ï¼Œæ‰€ä»¥æ— è®ºa_current æ€ä¹ˆå˜åŒ–ï¼Œç”¨æˆ·çš„æœ‰æ•ˆåŠ¨ä½œéƒ½æ˜¯å›ºå®šçš„ï¼ˆå› ä¸ºç”¨æˆ·åªå¯¹é‚£ä¸€æ‰¹itemæœ‰åé¦ˆï¼‰ã€‚
         æ­¤æ—¶ï¼Œa_currentå’Œa_valä¹‹é—´å°±æœ‰äº†gapï¼Œä¸ºäº†å¼¥è¡¥è¿™ä¸ªgapï¼Œè¿™é‡Œé€šè¿‡å­¦ä¹  mse(a_current,a_val),æ¥è®©a_current è¶‹å‘äºä¸a_valç›¸ä¼¼ï¼Œ
         ç„¶åå°±å¯ä»¥ä½¿ç”¨a_valçš„ä¿¡æ¯æ¥æ­£å¸¸çš„å­¦ä¹ æ›´æ–°ç½‘ç»œäº†ï¼Œè¿™é‡Œçš„r=sum(reward(ei))æ¥è‡ªa_valã€‚ï¼ˆä¹Ÿå°±æ˜¯åœ¨online trainningåŸºç¡€ä¸Šï¼Œé¢å¤–åŠ ä¸Šmseæ¥æ¶ˆé™¤a_currentå’Œa_valç›´æ¥çš„gap)
         
         
        è®­ç»ƒç®—æ³•ï¼š
            
            åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä½¿ç”¨çš„è¿˜æ˜¯ddpgç®—æ³•ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œcriticæ˜¯é‡‡ç”¨replay bufferæ¥batchè®­ç»ƒï¼Œè¿™é‡Œå°±æ¶‰åŠåˆ°ä¸€ä¸ªåŠ¨ä½œçš„é—®é¢˜ï¼Œè¿™é‡Œçš„åŠ¨ä½œéƒ½æ˜¯æ¥æºäºa_val,a=conv2d(a_val)ã€‚
            è€Œactorè®­ç»ƒä¸­çš„åŠ¨ä½œæ¥è‡ªäºa_current,a=conv2d(a_current),å› ä¸ºa_currentæ‰æ˜¯actorçš„çœŸå®è¾“å‡ºã€‚
          
        æµ‹è¯•æµç¨‹ï¼š
          
            onlineæµ‹è¯•æ—¶ï¼Œå°±æ˜¯è®¡ç®—çŠ¶æ€è·å–a_currentï¼Œå¾—åˆ°åŠ¨ä½œï¼Œè®¡ç®—a_valï¼Œè®¡ç®—å¥–åŠ±r=sum(reward(ei))ï¼Œå¾—åˆ°æ–°çŠ¶æ€ã€‚
            
            offlineæµ‹è¯•æ—¶ï¼Œå°±æ˜¯ç»™å®šä¸€ä¸ªsessionï¼Œç„¶åç®—æ³•èƒ½å°†ç”¨æˆ·ç‚¹å‡»/è´­ä¹°çš„itemæ’åˆ°å‰é¢ã€‚ä¹‹æ‰€ä»¥ä½¿ç”¨æ’åºæ¥éªŒè¯ï¼Œæ˜¯å› ä¸ºæˆ‘ä»¬åªæœ‰è¿™ä¸ªsessionçš„ground truth rewardã€‚
            æ•´ä½“ä¸Šä¹Ÿæ˜¯è®¡ç®—çŠ¶æ€è·å–a_currentï¼Œå¾—åˆ°åŠ¨ä½œï¼Œè®¡ç®—a_valï¼Œè®¡ç®—å¥–åŠ±r=sum(reward(ei))ï¼Œå¾—åˆ°æ–°çŠ¶æ€ã€‚
            
          
          
    
    
