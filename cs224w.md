## lecture 3.2  random walk approaches for node embeddings
  - notation
    - vector z<sub>u</sub>:
      - the embedding of node u(what we aim to find)
  - probability p(v|z<sub>u</sub> ) :
    - our model prediction based on z<sub>u</sub>
      - the The (predicted) probability of visiting node  v on random walks starting from node u.
  - random walk:
    - Given a graph and a starting point, we select a neighbor of it at random, and move to this neighbor; 
    - then we select a neighbor of this point at random, and move to it, etc.
    - The (random) sequence of points visited this way is a random walk on the graph.
  - z<sup>T</sup><sub>u</sub>z<sub>v</sub>
    - probability that u and v co-occur on  a random walk over the graph
  - why random walk
    - Expressivity: Flexible stochastic definition of node similarity that incorporates both local  and higher-order neighborhood information
      - Idea: if random walk starting from node u visits v with high probability, u and v are similar (high-order multi-hop information)
    - Efficiency: Do not need to consider all node pairs when training; only need to consider pairs that co-occur on random walks
  - optimization
    - give G=(V,E)
    - our goal is to learn mapping f(u) =  z<sub>u</sub>
    - Log-likelihood objective:
      - \sum_{u \epsilon v} log(p(N<sub>R</sub>(u)|z<sub>u</sub>)
        - N<sub>R</sub>(u) is the neighborhood of node  by strategy R 
